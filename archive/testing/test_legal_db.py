#!/usr/bin/env python3
"""
Comprehensive Test Suite for Legal Database System
Tests database functionality, AI analysis, and real-world data extraction
"""

import os
import sys
import json
import time
import logging
import sqlite3
import unittest
from datetime import datetime, timezone
from pathlib import Path

# Import our legal database system
from legal_database import LegalDatabase, EnhancedLegalAnalyzer, LegalDocument

# Import the main legal archive system
import importlib.util

def import_legal_scraper():
    """Import the legal scraper module"""
    try:
        spec = importlib.util.spec_from_file_location(
            "enhanced_legal_scraper", 
            "enhanced_legal_scraper (3).py"
        )
        enhanced_legal_scraper = importlib.util.module_from_spec(spec)
        spec.loader.exec_module(enhanced_legal_scraper)
        return enhanced_legal_scraper
    except Exception as e:
        print(f"Failed to import legal scraper: {e}")
        return None

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TestLegalDatabase(unittest.TestCase):
    """Test cases for Legal Database functionality"""
    
    def setUp(self):
        """Set up test environment"""
        self.test_db_path = "test_legal_archive.db"
        
        # Remove existing test database
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)
        
        # Initialize database and analyzer
        self.legal_db = LegalDatabase(self.test_db_path)
        self.legal_db.db_path = self.test_db_path
        self.legal_db._init_database()
        
        self.analyzer = EnhancedLegalAnalyzer()
        
        # Try to import legal archive system
        self.scraper_module = import_legal_scraper()
        self.legal_archive = None
        
        if self.scraper_module:
            try:
                self.legal_archive = self.scraper_module.UltraModernLegalArchive()
                logger.info("âœ… Legal archive system initialized for testing")
            except Exception as e:
                logger.warning(f"Could not initialize legal archive: {e}")

    def tearDown(self):
        """Clean up after tests"""
        if os.path.exists(self.test_db_path):
            os.remove(self.test_db_path)

    def test_database_initialization(self):
        """Test Case: Database initialization and schema"""
        logger.info("ğŸ§ª Testing database initialization...")
        
        # Check if table exists
        with sqlite3.connect(self.test_db_path) as conn:
            cursor = conn.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='legal_documents'
            """)
            self.assertTrue(cursor.fetchone(), "legal_documents table should exist")
        
        # Check table schema
        with sqlite3.connect(self.test_db_path) as conn:
            cursor = conn.execute("PRAGMA table_info(legal_documents)")
            columns = {row[1]: row[2] for row in cursor.fetchall()}
            
            expected_columns = {
                'id': 'INTEGER',
                'source': 'TEXT',
                'url': 'TEXT',
                'title': 'TEXT',
                'content': 'TEXT',
                'category': 'TEXT',
                'timestamp': 'DATETIME',
                'hash': 'TEXT',
                'analysis': 'TEXT',
                'reliability_score': 'REAL'
            }
            
            for col_name, col_type in expected_columns.items():
                self.assertIn(col_name, columns, f"Column {col_name} should exist")
        
        logger.info("âœ… Database initialization test passed")

    def test_majlis_document_fetch(self):
        """Test Case 1: Fetch and store document from Ù…Ø¬Ù„Ø³ Ø´ÙˆØ±Ø§ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ"""
        logger.info("ğŸ§ª Testing Majlis document fetch...")
        
        # Test document data
        test_url = "https://rc.majlis.ir/fa/law/show/139030"
        
        # Create sample document (simulating successful fetch)
        sample_doc = LegalDocument(
            source="Ù…Ø¬Ù„Ø³ Ø´ÙˆØ±Ø§ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ",
            url=test_url,
            title="Ù‚Ø§Ù†ÙˆÙ† Ù†Ù…ÙˆÙ†Ù‡ Ù…Ø¬Ù„Ø³ Ø´ÙˆØ±Ø§ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ",
            content="""
            Ù…Ø§Ø¯Ù‡ Û±- Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø¨Ù‡ Ù…Ù†Ø¸ÙˆØ± ØªÙ†Ø¸ÛŒÙ… Ø§Ù…ÙˆØ± Ù…Ø±Ø¨ÙˆØ· Ø¨Ù‡ Ø­Ù‚ÙˆÙ‚ Ø´Ù‡Ø±ÙˆÙ†Ø¯Ø§Ù† ÙˆØ¶Ø¹ Ø´Ø¯Ù‡ Ø§Ø³Øª.
            
            ØªØ¨ØµØ±Ù‡: Ù…Ù†Ø¸ÙˆØ± Ø§Ø² Ø´Ù‡Ø±ÙˆÙ†Ø¯ØŒ Ù‡Ø± Ø´Ø®Øµ Ø­Ù‚ÛŒÙ‚ÛŒ Ø§ÛŒØ±Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ ØªØ§Ø¨Ø¹ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¬Ù…Ù‡ÙˆØ±ÛŒ Ø§Ø³Ù„Ø§Ù…ÛŒ Ø§ÛŒØ±Ø§Ù† Ø¨Ø§Ø´Ø¯.
            
            Ù…Ø§Ø¯Ù‡ Û²- ÙˆØ²Ø§Ø±Øª Ø¯Ø§Ø¯Ú¯Ø³ØªØ±ÛŒ Ù…ÙˆØ¸Ù Ø§Ø³Øª Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø±Ø§ Ø§Ø¬Ø±Ø§ Ù†Ù…Ø§ÛŒØ¯.
            
            Ù…Ø§Ø¯Ù‡ Û³- Ø§ÛŒÙ† Ù‚Ø§Ù†ÙˆÙ† Ø§Ø² ØªØ§Ø±ÛŒØ® ØªØµÙˆÛŒØ¨ Ù„Ø§Ø²Ù…â€ŒØ§Ù„Ø§Ø¬Ø±Ø§ Ø§Ø³Øª.
            """,
            category="Ù‚Ø§Ù†ÙˆÙ†",
            reliability_score=0.98
        )
        
        # Analyze document
        analysis = self.analyzer.analyze_legal_document(
            sample_doc.content,
            sample_doc.title,
            sample_doc.source
        )
        sample_doc.analysis = json.dumps(analysis, ensure_ascii=False)
        
        # Insert document
        result = self.legal_db.insert_legal_document(sample_doc)
        self.assertTrue(result, "Document should be inserted successfully")
        
        # Verify insertion
        docs = self.legal_db.search_documents("Ù‚Ø§Ù†ÙˆÙ† Ù†Ù…ÙˆÙ†Ù‡")
        self.assertGreater(len(docs), 0, "Should find inserted document")
        
        # Check analysis results
        stored_doc = docs[0]
        stored_analysis = json.loads(stored_doc['analysis'])
        self.assertIn('classification', stored_analysis)
        self.assertIn('legal_entities', stored_analysis)
        
        logger.info("âœ… Majlis document fetch test passed")

    def test_nafaqe_definition_extraction(self):
        """Test Case 2: Extract Ù†ÙÙ‚Ù‡ definition"""
        logger.info("ğŸ§ª Testing Ù†ÙÙ‚Ù‡ definition extraction...")
        
        # Create comprehensive Ù†ÙÙ‚Ù‡ document
        nafaqe_doc = LegalDocument(
            source="Ú©Ø§Ù†ÙˆÙ† ÙˆÚ©Ù„Ø§ÛŒ Ø¯Ø§Ø¯Ú¯Ø³ØªØ±ÛŒ",
            url="https://icbar.ir/fa/legal/nafaqe-definition",
            title="ØªØ¹Ø±ÛŒÙ Ø¬Ø§Ù…Ø¹ Ù†ÙÙ‚Ù‡ Ø¯Ø± Ø­Ù‚ÙˆÙ‚ Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡",
            content="""
            Ù†ÙÙ‚Ù‡ Ø¯Ø± Ø§ØµØ·Ù„Ø§Ø­ Ø­Ù‚ÙˆÙ‚ÛŒ Ø¹Ø¨Ø§Ø±Øª Ø§Ø³Øª Ø§Ø² Ù…Ø®Ø§Ø±Ø¬ Ø¶Ø±ÙˆØ±ÛŒ Ø²Ù†Ø¯Ú¯ÛŒ Ú©Ù‡ Ø´ÙˆÙ‡Ø± Ù…ÙˆØ¸Ù Ø¨Ù‡ ØªØ£Ù…ÛŒÙ† Ø¢Ù† Ø¨Ø±Ø§ÛŒ Ù‡Ù…Ø³Ø± Ø®ÙˆØ¯ Ù…ÛŒâ€ŒØ¨Ø§Ø´Ø¯.
            
            Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø§Ø¯Ù‡ Û±Û±Û°Û¶ Ù‚Ø§Ù†ÙˆÙ† Ù…Ø¯Ù†ÛŒ Ø§ÛŒØ±Ø§Ù†: "Ø²Ù† Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± ØªÙ…Ú©ÛŒÙ†ØŒ Ø­Ù‚ Ù†ÙÙ‚Ù‡ Ø¯Ø§Ø±Ø¯ Ùˆ Ø´ÙˆÙ‡Ø± Ù…ÙˆØ¸Ù Ø§Ø³Øª 
            Ù…Ø¹ÛŒØ´Øª Ø§Ùˆ Ø±Ø§ Ø¨Ø± Ø­Ø³Ø¨ ÙˆØ³Ø¹ Ùˆ ØªÙˆØ§Ù† Ø®ÙˆØ¯ ØªØ£Ù…ÛŒÙ† Ú©Ù†Ø¯."
            
            Ø§Ù†ÙˆØ§Ø¹ Ù†ÙÙ‚Ù‡:
            Û±- Ù†ÙÙ‚Ù‡ Ø²ÙˆØ¬Ù‡: Ù†ÙÙ‚Ù‡â€ŒØ§ÛŒ Ú©Ù‡ Ø´ÙˆÙ‡Ø± Ø¨Ø§ÛŒØ¯ Ø¨Ù‡ Ù‡Ù…Ø³Ø± Ø®ÙˆØ¯ Ø¨Ù¾Ø±Ø¯Ø§Ø²Ø¯
            Û²- Ù†ÙÙ‚Ù‡ Ø§Ø·ÙØ§Ù„: Ù†ÙÙ‚Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙˆØ§Ù„Ø¯ÛŒÙ† Ù…ÙˆØ¸Ù Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ù† Ø¨Ø±Ø§ÛŒ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ø®ÙˆØ¯ Ù‡Ø³ØªÙ†Ø¯
            Û³- Ù†ÙÙ‚Ù‡ ÙˆØ§Ù„Ø¯ÛŒÙ†: Ù†ÙÙ‚Ù‡â€ŒØ§ÛŒ Ú©Ù‡ ÙØ±Ø²Ù†Ø¯Ø§Ù† Ù…ÙˆØ¸Ù Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ø¢Ù† Ø¨Ø±Ø§ÛŒ ÙˆØ§Ù„Ø¯ÛŒÙ† Ø®ÙˆØ¯ Ù‡Ø³ØªÙ†Ø¯
            
            Ø´Ø±Ø§ÛŒØ· Ø§Ø³ØªØ­Ù‚Ø§Ù‚ Ù†ÙÙ‚Ù‡:
            - ØªÙ…Ú©ÛŒÙ† Ø²ÙˆØ¬Ù‡ Ø§Ø² Ø²ÙˆØ¬
            - Ø¹Ø¯Ù… Ù†Ø§Ø´Ø²Ù‡ Ø¨ÙˆØ¯Ù† Ø²ÙˆØ¬Ù‡
            - Ø¹Ù‚Ø¯ ØµØ­ÛŒØ­ Ø¨ÛŒÙ† Ø²ÙˆØ¬ÛŒÙ†
            
            Ø¯Ø± ØµÙˆØ±Øª Ø§Ù…ØªÙ†Ø§Ø¹ Ø´ÙˆÙ‡Ø± Ø§Ø² Ù¾Ø±Ø¯Ø§Ø®Øª Ù†ÙÙ‚Ù‡ØŒ Ø²ÙˆØ¬Ù‡ Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø¨Ù‡ Ø¯Ø§Ø¯Ú¯Ø§Ù‡ Ù…Ø±Ø§Ø¬Ø¹Ù‡ Ú©Ø±Ø¯Ù‡ Ùˆ 
            Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ù„Ø²Ø§Ù… Ø¨Ù‡ Ù¾Ø±Ø¯Ø§Ø®Øª Ù†ÙÙ‚Ù‡ Ùˆ Ø­ØªÛŒ Ø·Ù„Ø§Ù‚ Ø¨Ù‡ Ø¹Ù„Øª Ø¹Ø¯Ù… Ù¾Ø±Ø¯Ø§Ø®Øª Ù†ÙÙ‚Ù‡ Ø±Ø§ Ù†Ù…Ø§ÛŒØ¯.
            
            Ù…ÛŒØ²Ø§Ù† Ù†ÙÙ‚Ù‡ Ø¨Ø± Ø§Ø³Ø§Ø³ ÙˆØ¶Ø¹ÛŒØª Ù…Ø§Ù„ÛŒ Ø´ÙˆÙ‡Ø± Ùˆ Ø¹Ø±Ù Ø§Ø¬ØªÙ…Ø§Ø¹ÛŒ ØªØ¹ÛŒÛŒÙ† Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø¯.
            """,
            category="Ù†ÙÙ‚Ù‡_Ùˆ_Ø­Ù‚ÙˆÙ‚_Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡",
            reliability_score=0.90
        )
        
        # Analyze document
        analysis = self.analyzer.analyze_legal_document(
            nafaqe_doc.content,
            nafaqe_doc.title,
            nafaqe_doc.source
        )
        nafaqe_doc.analysis = json.dumps(analysis, ensure_ascii=False)
        
        # Insert document
        result = self.legal_db.insert_legal_document(nafaqe_doc)
        self.assertTrue(result, "Ù†ÙÙ‚Ù‡ document should be inserted successfully")
        
        # Search for Ù†ÙÙ‚Ù‡
        search_results = self.legal_db.search_documents("Ù†ÙÙ‚Ù‡")
        self.assertGreater(len(search_results), 0, "Should find Ù†ÙÙ‚Ù‡ documents")
        
        # Verify content
        found_doc = search_results[0]
        self.assertIn("Ù†ÙÙ‚Ù‡", found_doc['content'])
        self.assertEqual(found_doc['category'], "Ù†ÙÙ‚Ù‡_Ùˆ_Ø­Ù‚ÙˆÙ‚_Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡")
        
        # Check analysis results
        stored_analysis = json.loads(found_doc['analysis'])
        self.assertIn('legal_entities', stored_analysis)
        self.assertIn('key_terms', stored_analysis)
        
        # Verify key terms extraction
        key_terms = stored_analysis.get('key_terms', [])
        nafaqe_terms = [term for term in key_terms if 'Ù†ÙÙ‚Ù‡' in term.get('term', '')]
        self.assertGreater(len(nafaqe_terms), 0, "Should extract Ù†ÙÙ‚Ù‡ as key term")
        
        logger.info("âœ… Ù†ÙÙ‚Ù‡ definition extraction test passed")

    def test_duplicate_url_handling(self):
        """Test Case 3: Verify duplicate URL handling using hash column"""
        logger.info("ğŸ§ª Testing duplicate URL handling...")
        
        # Create first document
        doc1 = LegalDocument(
            source="ØªØ³Øª",
            url="https://test.ir/duplicate-test",
            title="Ø³Ù†Ø¯ ØªØ³Øª",
            content="Ù…Ø­ØªÙˆØ§ÛŒ ØªØ³ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ",
            category="ØªØ³Øª",
            reliability_score=0.5
        )
        
        # Insert first document
        result1 = self.legal_db.insert_legal_document(doc1)
        self.assertTrue(result1, "First document should be inserted")
        
        # Create second document with same URL but different content
        doc2 = LegalDocument(
            source="ØªØ³Øª",
            url="https://test.ir/duplicate-test",  # Same URL
            title="Ø³Ù†Ø¯ ØªØ³Øª ÙˆÛŒØ±Ø§ÛŒØ´ Ø´Ø¯Ù‡",
            content="Ù…Ø­ØªÙˆØ§ÛŒ ØªØ³ØªÛŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ø´Ø¯Ù‡",  # Different content
            category="ØªØ³Øª",
            reliability_score=0.6
        )
        
        # Insert second document (should replace first due to URL uniqueness)
        result2 = self.legal_db.insert_legal_document(doc2)
        self.assertTrue(result2, "Second document should replace first")
        
        # Verify only one document exists
        with sqlite3.connect(self.test_db_path) as conn:
            count = conn.execute(
                "SELECT COUNT(*) FROM legal_documents WHERE url = ?", 
                (doc1.url,)
            ).fetchone()[0]
            self.assertEqual(count, 1, "Should have only one document with this URL")
        
        # Create third document with same content but different URL
        doc3 = LegalDocument(
            source="ØªØ³Øª",
            url="https://test.ir/different-url",  # Different URL
            title="Ø³Ù†Ø¯ ØªØ³Øª",
            content="Ù…Ø­ØªÙˆØ§ÛŒ ØªØ³ØªÛŒ ÙˆÛŒØ±Ø§ÛŒØ´ Ø´Ø¯Ù‡",  # Same content as doc2
            category="ØªØ³Øª",
            reliability_score=0.7
        )
        
        # This should be rejected due to content hash duplication
        result3 = self.legal_db.insert_legal_document(doc3)
        
        logger.info("âœ… Duplicate URL handling test passed")

    def test_ai_analysis_integration(self):
        """Test AI model integration and analysis"""
        logger.info("ğŸ§ª Testing AI analysis integration...")
        
        # Test document with legal content
        test_content = """
        Ù…Ø§Ø¯Ù‡ Û±Û±Û°Û¶ Ù‚Ø§Ù†ÙˆÙ† Ù…Ø¯Ù†ÛŒ - Ø²Ù† Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± ØªÙ…Ú©ÛŒÙ†ØŒ Ø­Ù‚ Ù†ÙÙ‚Ù‡ Ø¯Ø§Ø±Ø¯ Ùˆ Ø´ÙˆÙ‡Ø± Ù…ÙˆØ¸Ù Ø§Ø³Øª 
        Ù…Ø¹ÛŒØ´Øª Ø§Ùˆ Ø±Ø§ Ø¨Ø± Ø­Ø³Ø¨ ÙˆØ³Ø¹ Ùˆ ØªÙˆØ§Ù† Ø®ÙˆØ¯ ØªØ£Ù…ÛŒÙ† Ú©Ù†Ø¯.
        
        ØªØ¨ØµØ±Ù‡ - Ù†ÙÙ‚Ù‡ Ø´Ø§Ù…Ù„ Ø®ÙˆØ±Ø§Ú©ØŒ Ù¾ÙˆØ´Ø§Ú©ØŒ Ù…Ø³Ú©Ù† Ùˆ Ù…Ø®Ø§Ø±Ø¬ Ø¯Ø±Ù…Ø§Ù† Ø§Ø³Øª.
        """
        
        # Perform analysis
        analysis_result = self.analyzer.analyze_legal_document(
            test_content,
            "Ù…Ø§Ø¯Ù‡ Û±Û±Û°Û¶ Ù‚Ø§Ù†ÙˆÙ† Ù…Ø¯Ù†ÛŒ - Ø­Ù‚ Ù†ÙÙ‚Ù‡",
            "Ù‚Ø§Ù†ÙˆÙ† Ù…Ø¯Ù†ÛŒ"
        )
        
        # Check analysis structure
        self.assertIn('classification', analysis_result)
        self.assertIn('legal_entities', analysis_result)
        self.assertIn('key_terms', analysis_result)
        self.assertIn('word_count', analysis_result)
        
        # Check if Ù†ÙÙ‚Ù‡ is detected
        key_terms = analysis_result.get('key_terms', [])
        nafaqe_found = any('Ù†ÙÙ‚Ù‡' in term.get('term', '') for term in key_terms)
        self.assertTrue(nafaqe_found, "Should detect Ù†ÙÙ‚Ù‡ as key term")
        
        # Check legal entities
        entities = analysis_result.get('legal_entities', [])
        self.assertGreater(len(entities), 0, "Should extract legal entities")
        
        logger.info("âœ… AI analysis integration test passed")

    def test_full_text_search(self):
        """Test full-text search functionality"""
        logger.info("ğŸ§ª Testing full-text search...")
        
        # Insert test documents
        test_docs = [
            LegalDocument(
                source="ØªØ³Øª",
                url="https://test1.ir",
                title="Ù‚ÙˆØ§Ù†ÛŒÙ† Ù†ÙÙ‚Ù‡",
                content="Ù†ÙÙ‚Ù‡ Ø²ÙˆØ¬Ù‡ Ùˆ Ø­Ù‚ÙˆÙ‚ Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡",
                category="Ø­Ù‚ÙˆÙ‚_Ø®Ø§Ù†ÙˆØ§Ø¯Ù‡"
            ),
            LegalDocument(
                source="ØªØ³Øª",
                url="https://test2.ir",
                title="Ù‚ÙˆØ§Ù†ÛŒÙ† Ø§Ø±Ø«",
                content="Ù…ÛŒØ±Ø§Ø« Ùˆ ÙˆØµÛŒØª Ø¯Ø± Ø­Ù‚ÙˆÙ‚ Ø§ÛŒØ±Ø§Ù†",
                category="Ø­Ù‚ÙˆÙ‚_Ù…Ø§Ù„ÛŒ"
            ),
            LegalDocument(
                source="ØªØ³Øª",
                url="https://test3.ir",
                title="Ø¯Ø§Ø¯Ù†Ø§Ù…Ù‡ Ø·Ù„Ø§Ù‚",
                content="Ø­Ú©Ù… Ø·Ù„Ø§Ù‚ Ùˆ Ù†ÙÙ‚Ù‡ Ù…ØªØ¹Ù‡",
                category="Ø¯Ø§Ø¯Ù†Ø§Ù…Ù‡"
            )
        ]
        
        for doc in test_docs:
            analysis = self.analyzer.analyze_legal_document(doc.content, doc.title, doc.source)
            doc.analysis = json.dumps(analysis, ensure_ascii=False)
            self.legal_db.insert_legal_document(doc)
        
        # Test search queries
        search_tests = [
            ("Ù†ÙÙ‚Ù‡", 2),  # Should find 2 documents
            ("Ø§Ø±Ø«", 1),   # Should find 1 document
            ("Ø·Ù„Ø§Ù‚", 1),  # Should find 1 document
            ("xyz", 0)    # Should find 0 documents
        ]
        
        for query, expected_count in search_tests:
            results = self.legal_db.search_documents(query)
            self.assertEqual(
                len(results), expected_count, 
                f"Search for '{query}' should return {expected_count} results"
            )
        
        logger.info("âœ… Full-text search test passed")

class IntegrationTests:
    """Integration tests with real data"""
    
    def __init__(self):
        self.db_path = "integration_test_legal.db"
        self.legal_db = LegalDatabase(self.db_path)
        self.analyzer = EnhancedLegalAnalyzer()
        
        # Try to initialize legal archive
        scraper_module = import_legal_scraper()
        self.legal_archive = None
        
        if scraper_module:
            try:
                self.legal_archive = scraper_module.UltraModernLegalArchive()
                logger.info("âœ… Legal archive initialized for integration tests")
            except Exception as e:
                logger.warning(f"Legal archive not available for integration tests: {e}")

    def test_populate_database(self):
        """Test database population with sample data"""
        logger.info("ğŸ§ª Running database population test...")
        
        if not self.legal_archive:
            logger.warning("Skipping population test - legal archive not available")
            return
        
        # Populate database with limited data
        try:
            results = self.analyzer.populate_legal_database(self.legal_archive, max_docs_per_source=2)
            
            logger.info(f"Population results: {json.dumps(results, ensure_ascii=False, indent=2)}")
            
            # Verify some documents were processed
            assert results['total_processed'] > 0, "Should process some documents"
            
            # Check database stats
            stats = self.legal_db.get_database_stats()
            logger.info(f"Database stats: {json.dumps(stats, ensure_ascii=False, indent=2)}")
            
            logger.info("âœ… Database population test completed")
            
        except Exception as e:
            logger.error(f"Database population test failed: {e}")

    def test_nafaqe_search_and_extraction(self):
        """Test Ù†ÙÙ‚Ù‡ definition search and extraction"""
        logger.info("ğŸ§ª Testing Ù†ÙÙ‚Ù‡ definition search...")
        
        try:
            # Search for Ù†ÙÙ‚Ù‡ definition
            nafaqe_doc = self.analyzer.search_nafaqe_definition(self.legal_archive)
            
            if nafaqe_doc:
                logger.info("âœ… Ù†ÙÙ‚Ù‡ definition found/created successfully")
                
                # Verify the document contains Ù†ÙÙ‚Ù‡ information
                if isinstance(nafaqe_doc, dict):
                    content = nafaqe_doc.get('content', '')
                else:
                    content = nafaqe_doc.content
                
                assert 'Ù†ÙÙ‚Ù‡' in content, "Document should contain Ù†ÙÙ‚Ù‡ information"
                logger.info("âœ… Ù†ÙÙ‚Ù‡ content verification passed")
                
                # Search in database
                search_results = self.legal_db.search_documents("Ù†ÙÙ‚Ù‡")
                assert len(search_results) > 0, "Should find Ù†ÙÙ‚Ù‡ documents in database"
                
                logger.info(f"Found {len(search_results)} Ù†ÙÙ‚Ù‡-related documents")
                
                # Display sample Ù†ÙÙ‚Ù‡ information
                for doc in search_results[:2]:
                    logger.info(f"ğŸ“„ Ù†ÙÙ‚Ù‡ Document: {doc['title']}")
                    logger.info(f"   Source: {doc['source']}")
                    logger.info(f"   Category: {doc['category']}")
                    logger.info(f"   Content preview: {doc['content'][:200]}...")
            
            else:
                logger.warning("Could not find or create Ù†ÙÙ‚Ù‡ definition")
        
        except Exception as e:
            logger.error(f"Ù†ÙÙ‚Ù‡ search test failed: {e}")

    def run_all_tests(self):
        """Run all integration tests"""
        logger.info("ğŸš€ Starting integration tests...")
        
        try:
            self.test_populate_database()
            self.test_nafaqe_search_and_extraction()
            
            # Display final database statistics
            stats = self.legal_db.get_database_stats()
            logger.info("ğŸ“Š Final Database Statistics:")
            logger.info(f"   Total Documents: {stats.get('total_documents', 0)}")
            logger.info(f"   Sources: {list(stats.get('sources', {}).keys())}")
            logger.info(f"   Categories: {list(stats.get('categories', {}).keys())}")
            
            logger.info("âœ… All integration tests completed")
            
        except Exception as e:
            logger.error(f"Integration tests failed: {e}")
        
        finally:
            # Clean up
            if os.path.exists(self.db_path):
                try:
                    os.remove(self.db_path)
                    logger.info("ğŸ§¹ Test database cleaned up")
                except:
                    pass

def run_comprehensive_tests():
    """Run comprehensive test suite"""
    print("ğŸ›ï¸ Iranian Legal Archive - Database Test Suite")
    print("=" * 60)
    print(f"ğŸ“… Test Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} CEST")
    print()
    
    # Run unit tests
    print("ğŸ§ª Running Unit Tests...")
    unittest.main(argv=[''], exit=False, verbosity=2)
    
    print("\nğŸ”— Running Integration Tests...")
    integration_tests = IntegrationTests()
    integration_tests.run_all_tests()
    
    print("\nâœ… Test suite completed!")

if __name__ == "__main__":
    # Setup test environment
    os.environ.update({
        'TRANSFORMERS_CACHE': '/tmp/test_hf_cache',
        'HF_HOME': '/tmp/test_hf_cache',
        'TORCH_HOME': '/tmp/test_torch_cache',
        'TOKENIZERS_PARALLELISM': 'false'
    })
    
    run_comprehensive_tests()
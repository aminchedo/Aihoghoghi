#!/usr/bin/env python3
"""
Comprehensive Verification Report Generator
Compiles all test results into final assessment report
"""

import json
import datetime
import os
from typing import Dict, List, Any

class ComprehensiveReportGenerator:
    def __init__(self):
        self.timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # Load all test results
        self.test_results = {}
        self.load_all_test_results()
        
        self.final_report = {
            "report_timestamp": datetime.datetime.now().isoformat(),
            "executive_summary": {},
            "section_1_github_pages": {},
            "section_2_system_components": {},
            "section_3_operational_status": {},
            "section_4_evidence_package": {},
            "section_5_final_verdict": {}
        }

    def load_all_test_results(self):
        """Load all test result files"""
        result_files = [
            ("github_pages", "github_pages_verification_"),
            ("scraping", "real_scraping_test_"),
            ("ai_system", "real_ai_test_"),
            ("database", "database_verification_"),
            ("integration", "integration_test_"),
            ("web_interface", "web_interface_test_")
        ]
        
        for test_type, file_prefix in result_files:
            # Find the most recent file for each test type
            matching_files = [f for f in os.listdir('.') if f.startswith(file_prefix) and f.endswith('.json')]
            
            if matching_files:
                # Get the most recent file
                latest_file = sorted(matching_files)[-1]
                
                try:
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        self.test_results[test_type] = json.load(f)
                        print(f"‚úÖ Loaded {test_type} results from {latest_file}")
                except Exception as e:
                    print(f"‚ùå Failed to load {test_type} results: {e}")
                    self.test_results[test_type] = {"error": str(e)}
            else:
                print(f"‚ö†Ô∏è  No results found for {test_type}")
                self.test_results[test_type] = {"error": "No test results found"}

    def generate_executive_summary(self):
        """Generate executive summary of all findings"""
        print("üìã Generating executive summary...")
        
        summary = {
            "overall_system_status": "UNKNOWN",
            "critical_findings": [],
            "key_successes": [],
            "deployment_reality": "NON_FUNCTIONAL",
            "credibility_assessment": "LOW",
            "user_readiness": "NOT_READY"
        }
        
        # Analyze GitHub Pages deployment
        github_results = self.test_results.get("github_pages", {})
        github_verdict = github_results.get("final_verdict", {})
        
        if not github_verdict.get("overall_functional", False):
            summary["critical_findings"].append("üö® CRITICAL: GitHub Pages deployment is completely non-functional (404 error)")
            summary["deployment_reality"] = "NON_EXISTENT"
        
        # Analyze scraping system
        scraping_results = self.test_results.get("scraping", {})
        scraping_analysis = scraping_results.get("success_rate_analysis", {})
        
        actual_scraping_rate = scraping_analysis.get("actual_scraping_success", 0)
        if actual_scraping_rate >= 80:
            summary["key_successes"].append(f"‚úÖ Scraping system achieves {actual_scraping_rate}% success rate (matches claim)")
        elif actual_scraping_rate >= 60:
            summary["key_successes"].append(f"‚ö†Ô∏è  Scraping system achieves {actual_scraping_rate}% success rate (below 80% claim)")
        else:
            summary["critical_findings"].append(f"‚ùå Scraping system only achieves {actual_scraping_rate}% success rate")
            
        # Analyze AI system
        ai_results = self.test_results.get("ai_system", {})
        ai_performance = ai_results.get("ai_performance_metrics", {})
        
        ai_success_rate = ai_performance.get("overall_success_rate", 0)
        if ai_success_rate >= 80:
            summary["key_successes"].append(f"‚úÖ AI system functional with {ai_success_rate}% success rate")
        else:
            summary["critical_findings"].append(f"‚ùå AI system non-functional ({ai_success_rate}% success rate)")
            
        # Analyze database system
        database_results = self.test_results.get("database", {})
        db_discovery = database_results.get("database_discovery", {})
        
        valid_dbs = db_discovery.get("valid_sqlite_files", 0)
        if valid_dbs > 0:
            summary["key_successes"].append(f"‚úÖ Database system functional with {valid_dbs} SQLite databases")
        else:
            summary["critical_findings"].append("‚ùå No functional database system found")
            
        # Analyze web interface
        interface_results = self.test_results.get("web_interface", {})
        interface_completeness = interface_results.get("interface_completeness", {})
        
        ux_score = interface_completeness.get("user_experience_score", 0)
        if ux_score >= 80:
            summary["key_successes"].append(f"‚úÖ Excellent web interface (UX Score: {ux_score}/100)")
        elif ux_score >= 60:
            summary["key_successes"].append(f"‚ö†Ô∏è  Good web interface (UX Score: {ux_score}/100)")
        else:
            summary["critical_findings"].append(f"‚ùå Poor web interface (UX Score: {ux_score}/100)")
            
        # Analyze integration
        integration_results = self.test_results.get("integration", {})
        integration_success = integration_results.get("integration_success", False)
        
        if integration_success:
            summary["key_successes"].append("‚úÖ End-to-end integration functional")
        else:
            summary["critical_findings"].append("‚ùå End-to-end integration broken")
            
        # Determine overall status
        critical_count = len(summary["critical_findings"])
        success_count = len(summary["key_successes"])
        
        if critical_count == 0 and success_count >= 4:
            summary["overall_system_status"] = "FULLY_FUNCTIONAL"
            summary["credibility_assessment"] = "HIGH"
            summary["user_readiness"] = "READY"
        elif critical_count <= 1 and success_count >= 3:
            summary["overall_system_status"] = "MOSTLY_FUNCTIONAL"
            summary["credibility_assessment"] = "MEDIUM"
            summary["user_readiness"] = "PARTIALLY_READY"
        elif success_count >= 2:
            summary["overall_system_status"] = "PARTIALLY_FUNCTIONAL"
            summary["credibility_assessment"] = "MEDIUM"
            summary["user_readiness"] = "NOT_READY"
        else:
            summary["overall_system_status"] = "NON_FUNCTIONAL"
            summary["credibility_assessment"] = "LOW"
            summary["user_readiness"] = "NOT_READY"
            
        self.final_report["executive_summary"] = summary
        return summary

    def generate_github_pages_section(self):
        """Generate detailed GitHub Pages analysis"""
        print("üåê Generating GitHub Pages section...")
        
        github_results = self.test_results.get("github_pages", {})
        deployment_status = github_results.get("deployment_status", {})
        
        github_section = {
            "url_tested": "https://aminchedo.github.io/Aihoghogh/",
            "accessibility_verification": {
                "site_loads_successfully": deployment_status.get("url_accessible", False),
                "evidence": f"HTTP {deployment_status.get('http_status_code', 'Unknown')}",
                "load_time_measurements": deployment_status.get("load_time_seconds", "N/A"),
                "mobile_compatibility": "UNTESTED - Site not accessible",
                "cross_browser_functionality": "UNTESTED - Site not accessible"
            },
            "interface_functionality_reality": {
                "start_scraping_button": "NON_FUNCTIONAL - Site not accessible",
                "analyze_content_button": "NON_FUNCTIONAL - Site not accessible", 
                "complete_test_button": "NON_FUNCTIONAL - Site not accessible",
                "real_stats_button": "NON_FUNCTIONAL - Site not accessible",
                "real_time_updates": "NOT_WORKING - Site not accessible"
            },
            "backend_connectivity_status": {
                "api_endpoints_accessible": "NO - All endpoints return 404",
                "database_operations_functional": "NO - Backend not accessible",
                "persian_text_processing": "UNKNOWN - Cannot test due to 404",
                "error_handling": "UNKNOWN - Cannot test due to 404"
            },
            "usability_assessment": {
                "user_can_complete_workflow": "NO - Site completely inaccessible",
                "persian_language_support": "UNKNOWN - Cannot verify",
                "navigation_intuitive": "UNKNOWN - Cannot test",
                "system_responsive": "NON_FUNCTIONAL - 404 error"
            }
        }
        
        self.final_report["section_1_github_pages"] = github_section
        return github_section

    def generate_system_components_section(self):
        """Generate system components verification"""
        print("‚öôÔ∏è  Generating system components section...")
        
        components_section = {
            "web_scraping_validation": {},
            "ai_system_verification": {},
            "database_operations_test": {},
            "system_integration_test": {},
            "web_interface_validation": {}
        }
        
        # Web scraping validation
        scraping_results = self.test_results.get("scraping", {})
        iranian_scraping = scraping_results.get("iranian_site_scraping", {})
        dns_tests = scraping_results.get("dns_server_tests", {})
        cors_tests = scraping_results.get("cors_proxy_tests", {})
        
        components_section["web_scraping_validation"] = {
            "dns_servers_tested": f"{dns_tests.get('functional_servers', 0)}/22",
            "iranian_sites_success": f"{iranian_scraping.get('successful_scrapes', 0)}/5",
            "cors_proxy_methods": f"{cors_tests.get('functional_methods', 0)}/7",
            "actual_success_rate": f"{iranian_scraping.get('actual_success_rate_percent', 0)}%",
            "claimed_vs_actual": "MATCHES" if iranian_scraping.get('actual_success_rate_percent', 0) >= 80 else "BELOW_CLAIMS",
            "content_extracted": f"{iranian_scraping.get('total_content_extracted', 0):,} characters",
            "arvancloud_bypass": "PARTIALLY_SUCCESSFUL" if iranian_scraping.get('arvancloud_403_encountered') else "NOT_TESTED"
        }
        
        # AI system verification
        ai_results = self.test_results.get("ai_system", {})
        ai_performance = ai_results.get("ai_performance_metrics", {})
        entity_tests = ai_results.get("entity_extraction_tests", {})
        cat_tests = ai_results.get("categorization_tests", {})
        
        components_section["ai_system_verification"] = {
            "huggingface_api_accessible": ai_results.get("huggingface_api_tests", {}).get("api_accessible", False),
            "persian_bert_functional": ai_results.get("persian_bert_tests", {}).get("model_accessible", False),
            "entity_extraction_working": entity_tests.get("entities_extracted", 0) > 0,
            "text_categorization_working": cat_tests.get("category_coverage", 0) > 0,
            "overall_ai_success_rate": f"{ai_performance.get('overall_success_rate', 0)}%",
            "entities_extracted_total": entity_tests.get("entities_extracted", 0),
            "categories_supported": f"{cat_tests.get('category_coverage', 0)}/4"
        }
        
        # Database operations test
        database_results = self.test_results.get("database", {})
        db_discovery = database_results.get("database_discovery", {})
        db_operations = database_results.get("database_operations", {})
        
        components_section["database_operations_test"] = {
            "sqlite_databases_found": db_discovery.get("valid_sqlite_files", 0),
            "total_database_size": f"{db_discovery.get('total_size_mb', 0)} MB",
            "crud_operations_working": "4/4" if all(
                db_operations.get(f"{op}_operations", {}).get("success", False) 
                for op in ["insert", "select", "update", "delete"]
            ) else "PARTIAL",
            "persian_text_support": "YES" if db_operations.get("persian_text_support", False) else "NO",
            "data_persistence_verified": database_results.get("data_persistence", {}).get("persistence_test_passed", False),
            "total_records": database_results.get("data_persistence", {}).get("total_records_across_dbs", 0)
        }
        
        # Integration test
        integration_results = self.test_results.get("integration", {})
        integration_metrics = integration_results.get("end_to_end_metrics", {})
        
        components_section["system_integration_test"] = {
            "pipeline_success": integration_results.get("integration_success", False),
            "overall_success_rate": f"{integration_metrics.get('overall_success_rate', 0)}%",
            "total_processing_time": f"{integration_metrics.get('total_pipeline_time', 0)}s",
            "data_flow_integrity": integration_metrics.get("data_flow_integrity", False),
            "performance_grade": integration_metrics.get("performance_grade", "F")
        }
        
        # Web interface validation
        interface_results = self.test_results.get("web_interface", {})
        interface_completeness = interface_results.get("interface_completeness", {})
        button_functionality = interface_results.get("button_functionality", {})
        
        components_section["web_interface_validation"] = {
            "html_files_analyzed": interface_results.get("html_files_analysis", {}).get("total_html_files", 0),
            "main_interface_identified": interface_results.get("html_files_analysis", {}).get("main_interface_identified", "None"),
            "documented_buttons_found": f"{button_functionality.get('total_buttons_found', 0)}/4",
            "functional_buttons_estimated": button_functionality.get("functional_buttons_estimated", 0),
            "persian_rtl_support": "COMPLETE" if interface_results.get("persian_support", {}).get("rtl_direction_set", False) else "MISSING",
            "javascript_functionality": f"{interface_results.get('javascript_analysis', {}).get('total_js_functions', 0)} functions",
            "ux_score": f"{interface_completeness.get('user_experience_score', 0)}/100",
            "production_ready": interface_completeness.get("production_ready", False)
        }
        
        self.final_report["section_2_system_components"] = components_section
        return components_section

    def generate_operational_status_summary(self):
        """Generate operational status assessment"""
        print("üéØ Generating operational status summary...")
        
        operational_status = {
            "overall_system_status": "UNKNOWN",
            "user_experience_reality": {},
            "deployment_quality": {},
            "functionality_matrix": {}
        }
        
        # Determine overall system status
        github_functional = self.test_results.get("github_pages", {}).get("final_verdict", {}).get("overall_functional", False)
        scraping_functional = self.test_results.get("scraping", {}).get("success_rate_analysis", {}).get("actual_scraping_success", 0) >= 60
        ai_functional = self.test_results.get("ai_system", {}).get("ai_performance_metrics", {}).get("overall_success_rate", 0) >= 60
        database_functional = self.test_results.get("database", {}).get("database_operations", {}).get("insert_operations", {}).get("success", False)
        integration_functional = self.test_results.get("integration", {}).get("integration_success", False)
        interface_functional = self.test_results.get("web_interface", {}).get("interface_completeness", {}).get("production_ready", False)
        
        functional_components = sum([scraping_functional, ai_functional, database_functional, integration_functional, interface_functional])
        
        if github_functional and functional_components >= 4:
            operational_status["overall_system_status"] = "FULLY_OPERATIONAL"
        elif functional_components >= 4:
            operational_status["overall_system_status"] = "LOCALLY_FUNCTIONAL_NOT_DEPLOYED"
        elif functional_components >= 3:
            operational_status["overall_system_status"] = "PARTIALLY_FUNCTIONAL"
        else:
            operational_status["overall_system_status"] = "NON_FUNCTIONAL"
            
        # User experience reality
        operational_status["user_experience_reality"] = {
            "can_scrape_legal_documents": "YES" if scraping_functional else "NO",
            "can_get_ai_analysis": "LIMITED" if ai_functional else "NO",
            "can_view_statistics": "YES" if database_functional else "NO", 
            "system_delivers_promises": "PARTIALLY" if functional_components >= 3 else "NO"
        }
        
        # Deployment quality
        operational_status["deployment_quality"] = {
            "github_pages_status": "NON_EXISTENT",
            "local_system_status": "FUNCTIONAL" if functional_components >= 3 else "BROKEN",
            "production_ready": interface_functional and database_functional and scraping_functional,
            "demo_prototype_level": functional_components >= 2,
            "non_functional_showcase": functional_components < 2
        }
        
        # Functionality matrix
        operational_status["functionality_matrix"] = {
            "github_pages_deployment": "‚ùå NON_EXISTENT",
            "web_scraping_system": "‚úÖ FUNCTIONAL" if scraping_functional else "‚ùå BROKEN",
            "ai_analysis_system": "‚ö†Ô∏è  LIMITED" if ai_functional else "‚ùå BROKEN",
            "database_operations": "‚úÖ FUNCTIONAL" if database_functional else "‚ùå BROKEN",
            "web_interface": "‚úÖ EXCELLENT" if interface_functional else "‚ùå POOR",
            "system_integration": "‚ö†Ô∏è  PARTIAL" if integration_functional else "‚ùå BROKEN"
        }
        
        self.final_report["section_3_operational_status"] = operational_status
        return operational_status

    def generate_evidence_package(self):
        """Generate evidence package summary"""
        print("üì¶ Generating evidence package...")
        
        evidence = {
            "test_files_generated": [],
            "verification_reports": [],
            "concrete_measurements": {},
            "screenshots_captured": False,
            "network_logs_captured": True,
            "performance_data_captured": True
        }
        
        # List all generated test files
        test_files = [f for f in os.listdir('.') if any(
            f.startswith(prefix) for prefix in [
                'github_pages_verification_',
                'real_scraping_test_',
                'real_ai_test_',
                'database_verification_',
                'integration_test_',
                'web_interface_test_'
            ]
        )]
        
        evidence["test_files_generated"] = test_files
        evidence["verification_reports"] = [f for f in test_files if f.endswith('.json')]
        
        # Compile concrete measurements
        evidence["concrete_measurements"] = {
            "github_pages_response": "404 Not Found",
            "scraping_success_rate": f"{self.test_results.get('scraping', {}).get('success_rate_analysis', {}).get('actual_scraping_success', 0)}%",
            "dns_servers_functional": f"{self.test_results.get('scraping', {}).get('dns_server_tests', {}).get('functional_servers', 0)}/22",
            "database_files_found": self.test_results.get('database', {}).get('database_discovery', {}).get('valid_sqlite_files', 0),
            "total_database_records": self.test_results.get('database', {}).get('data_persistence', {}).get('total_records_across_dbs', 0),
            "html_files_analyzed": self.test_results.get('web_interface', {}).get('html_files_analysis', {}).get('total_html_files', 0),
            "javascript_functions": self.test_results.get('web_interface', {}).get('javascript_analysis', {}).get('total_js_functions', 0),
            "persian_text_support": "VERIFIED" if self.test_results.get('web_interface', {}).get('persian_support', {}).get('unicode_support', False) else "NOT_VERIFIED"
        }
        
        self.final_report["section_4_evidence_package"] = evidence
        return evidence

    def generate_final_verdict(self):
        """Generate final verdict and recommendations"""
        print("‚öñÔ∏è  Generating final verdict...")
        
        verdict = {
            "truth_vs_claims_analysis": {},
            "immediate_action_items": [],
            "credibility_assessment": {},
            "ultimate_answer": ""
        }
        
        # Truth vs Claims Analysis
        claims_analysis = {
            "github_pages_deployment": {
                "claimed": "Deployed and functional at https://aminchedo.github.io/Aihoghogh/",
                "actual": "NON-EXISTENT - Returns 404 error",
                "verdict": "FALSE CLAIM"
            },
            "80_percent_scraping_success": {
                "claimed": "80% scraping success rate",
                "actual": f"{self.test_results.get('scraping', {}).get('success_rate_analysis', {}).get('actual_scraping_success', 0)}%",
                "verdict": "VERIFIED" if self.test_results.get('scraping', {}).get('success_rate_analysis', {}).get('actual_scraping_success', 0) >= 80 else "UNVERIFIED"
            },
            "22_dns_servers": {
                "claimed": "22 DNS servers for bypass",
                "actual": f"{self.test_results.get('scraping', {}).get('dns_server_tests', {}).get('functional_servers', 0)}/22 functional",
                "verdict": "VERIFIED" if self.test_results.get('scraping', {}).get('dns_server_tests', {}).get('functional_servers', 0) >= 20 else "PARTIALLY_VERIFIED"
            },
            "persian_bert_ai": {
                "claimed": "HuggingFace Persian BERT integration",
                "actual": "API accessible but models require authentication/warm-up",
                "verdict": "PARTIALLY_VERIFIED"
            },
            "no_loading_issues": {
                "claimed": "Functional web interface without loading issues",
                "actual": "Local interface excellent, but GitHub Pages non-existent",
                "verdict": "MISLEADING"
            }
        }
        
        verdict["truth_vs_claims_analysis"] = claims_analysis
        
        # Immediate action items
        verdict["immediate_action_items"] = [
            "üö® CRITICAL: Deploy actual GitHub Pages site or remove deployment claims",
            "üîß Fix HuggingFace API authentication for Persian BERT models",
            "üì± Test mobile responsiveness with actual browser testing",
            "üîó Implement actual backend API endpoints for production deployment",
            "üìä Add real-time data updates to match interface claims"
        ]
        
        # Credibility assessment
        false_claims = sum(1 for claim in claims_analysis.values() if claim["verdict"] == "FALSE CLAIM")
        verified_claims = sum(1 for claim in claims_analysis.values() if claim["verdict"] == "VERIFIED")
        total_claims = len(claims_analysis)
        
        credibility_score = (verified_claims / total_claims) * 100
        
        verdict["credibility_assessment"] = {
            "verified_claims": f"{verified_claims}/{total_claims}",
            "false_claims": f"{false_claims}/{total_claims}",
            "credibility_score": f"{credibility_score:.1f}%",
            "trust_level": "HIGH" if credibility_score >= 80 else "MEDIUM" if credibility_score >= 60 else "LOW",
            "commercial_readiness": "NOT_READY" if false_claims > 0 else "READY"
        }
        
        # Ultimate answer
        github_functional = self.test_results.get("github_pages", {}).get("final_verdict", {}).get("overall_functional", False)
        
        if github_functional:
            verdict["ultimate_answer"] = "YES - User can successfully use the system at the GitHub Pages URL"
        else:
            local_functional = sum([
                self.test_results.get('scraping', {}).get('success_rate_analysis', {}).get('actual_scraping_success', 0) >= 60,
                self.test_results.get('database', {}).get('database_operations', {}).get('insert_operations', {}).get('success', False),
                self.test_results.get('web_interface', {}).get('interface_completeness', {}).get('production_ready', False)
            ]) >= 2
            
            if local_functional:
                verdict["ultimate_answer"] = "NO - GitHub Pages deployment is non-existent, but local system is functional. Users cannot access the system at the claimed URL, but the underlying technology works."
            else:
                verdict["ultimate_answer"] = "NO - System is not accessible to users and has significant functionality issues."
        
        self.final_report["section_5_final_verdict"] = verdict
        return verdict

    def generate_complete_report(self):
        """Generate the complete verification report"""
        print("üöÄ Generating Comprehensive Verification Report...")
        print("=" * 80)
        
        try:
            # Generate all sections
            self.generate_executive_summary()
            self.generate_github_pages_section()
            self.generate_system_components_section()
            self.generate_operational_status_summary()
            self.generate_evidence_package()
            self.generate_final_verdict()
            
            # Save complete report
            report_path = f"/workspace/COMPREHENSIVE_VERIFICATION_REPORT_{self.timestamp}.json"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(self.final_report, f, ensure_ascii=False, indent=2)
                
            # Generate human-readable summary
            self.generate_human_readable_report()
            
            print(f"\n‚úÖ Comprehensive report generated: {report_path}")
            return self.final_report
            
        except Exception as e:
            print(f"‚ùå Report generation failed: {e}")
            return {"error": str(e)}

    def generate_human_readable_report(self):
        """Generate human-readable summary report"""
        summary_path = f"/workspace/VERIFICATION_SUMMARY_{self.timestamp}.txt"
        
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("=" * 100 + "\n")
            f.write("üáÆüá∑ IRANIAN LEGAL ARCHIVE SYSTEM - COMPREHENSIVE VERIFICATION REPORT\n")
            f.write("=" * 100 + "\n")
            f.write(f"üìÖ Report Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"üéØ URL Tested: https://aminchedo.github.io/Aihoghogh/\n\n")
            
            # Executive Summary
            exec_summary = self.final_report["executive_summary"]
            f.write("üìã EXECUTIVE SUMMARY\n")
            f.write("-" * 50 + "\n")
            f.write(f"üèÜ Overall Status: {exec_summary['overall_system_status']}\n")
            f.write(f"üîí Credibility: {exec_summary['credibility_assessment']}\n")
            f.write(f"üë§ User Ready: {exec_summary['user_readiness']}\n")
            f.write(f"üåê Deployment: {exec_summary['deployment_reality']}\n\n")
            
            # Critical Findings
            if exec_summary["critical_findings"]:
                f.write("‚ùå CRITICAL FINDINGS:\n")
                for finding in exec_summary["critical_findings"]:
                    f.write(f"   {finding}\n")
                f.write("\n")
                
            # Key Successes
            if exec_summary["key_successes"]:
                f.write("‚úÖ KEY SUCCESSES:\n")
                for success in exec_summary["key_successes"]:
                    f.write(f"   {success}\n")
                f.write("\n")
                
            # GitHub Pages Section
            github_section = self.final_report["section_1_github_pages"]
            f.write("üåê GITHUB PAGES DEPLOYMENT STATUS\n")
            f.write("-" * 50 + "\n")
            f.write(f"üéØ URL Tested: {github_section['url_tested']}\n")
            f.write(f"üì° Site Loads: {github_section['accessibility_verification']['site_loads_successfully']}\n")
            f.write(f"üìä HTTP Status: {github_section['accessibility_verification']['evidence']}\n")
            f.write(f"‚ö° Load Time: {github_section['accessibility_verification']['load_time_measurements']}\n\n")
            
            # System Components
            components = self.final_report["section_2_system_components"]
            f.write("‚öôÔ∏è  SYSTEM COMPONENTS VERIFICATION\n")
            f.write("-" * 50 + "\n")
            
            scraping = components["web_scraping_validation"]
            f.write(f"üï∑Ô∏è  Scraping: {scraping['actual_success_rate']} success ({scraping['iranian_sites_success']} sites)\n")
            f.write(f"üåê DNS Servers: {scraping['dns_servers_tested']} functional\n")
            f.write(f"üîó CORS Proxies: {scraping['cors_proxy_methods']} working\n")
            
            ai = components["ai_system_verification"]
            f.write(f"ü§ñ AI System: {ai['overall_ai_success_rate']} success rate\n")
            f.write(f"üîç Entity Extraction: {ai['entities_extracted_total']} entities found\n")
            f.write(f"üìÇ Categories: {ai['categories_supported']} supported\n")
            
            database = components["database_operations_test"]
            f.write(f"üíæ Database: {database['sqlite_databases_found']} SQLite files ({database['total_database_size']})\n")
            f.write(f"üîÑ CRUD Operations: {database['crud_operations_working']}\n")
            f.write(f"üáÆüá∑ Persian Support: {database['persian_text_support']}\n")
            
            interface = components["web_interface_validation"]
            f.write(f"üé® Web Interface: {interface['ux_score']} UX score\n")
            f.write(f"üîò Buttons: {interface['documented_buttons_found']} found, {interface['functional_buttons_estimated']} functional\n")
            f.write(f"üì± Production Ready: {interface['production_ready']}\n\n")
            
            # Final Verdict
            final_verdict = self.final_report["section_5_final_verdict"]
            f.write("‚öñÔ∏è  FINAL VERDICT\n")
            f.write("-" * 50 + "\n")
            
            credibility = final_verdict["credibility_assessment"]
            f.write(f"üéØ Credibility Score: {credibility['credibility_score']}\n")
            f.write(f"‚úÖ Verified Claims: {credibility['verified_claims']}\n")
            f.write(f"‚ùå False Claims: {credibility['false_claims']}\n")
            f.write(f"üè™ Commercial Ready: {credibility['commercial_readiness']}\n\n")
            
            f.write("üéØ ULTIMATE ANSWER:\n")
            f.write(f"{final_verdict['ultimate_answer']}\n\n")
            
            f.write("=" * 100 + "\n")
            
        print(f"üìÑ Human-readable summary saved: {summary_path}")

    def print_final_summary(self):
        """Print final verification summary"""
        print("\n" + "=" * 100)
        print("üèÜ COMPREHENSIVE VERIFICATION COMPLETE")
        print("=" * 100)
        
        exec_summary = self.final_report["executive_summary"]
        final_verdict = self.final_report["section_5_final_verdict"]
        
        print(f"üéØ OVERALL STATUS: {exec_summary['overall_system_status']}")
        print(f"üîí CREDIBILITY: {exec_summary['credibility_assessment']}")
        print(f"üë§ USER READY: {exec_summary['user_readiness']}")
        
        print(f"\nüéØ ULTIMATE ANSWER:")
        print(f"{final_verdict['ultimate_answer']}")
        
        print(f"\nüìä COMPONENT STATUS:")
        operational = self.final_report["section_3_operational_status"]
        functionality_matrix = operational["functionality_matrix"]
        
        for component, status in functionality_matrix.items():
            print(f"   {component}: {status}")
            
        print("\n" + "=" * 100)

def main():
    """Main execution function"""
    generator = ComprehensiveReportGenerator()
    generator.generate_complete_report()
    generator.print_final_summary()

if __name__ == "__main__":
    main()